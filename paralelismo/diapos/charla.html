<!DOCTYPE html>
<html>
  <head>
    <title>Threading y paralelismo</title>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
    <style type="text/css">
      @import url(http://fonts.googleapis.com/css?family=Yanone+Kaffeesatz);
      @import url(http://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic);
      @import url(http://fonts.googleapis.com/css?family=Ubuntu+Mono:400,700,400italic);

      body { font-family: 'Droid Serif'; }
      h1, h2, h3 {
        font-family: 'Yanone Kaffeesatz';
        font-weight: normal;
      }
      .remark-code, .remark-inline-code { font-family: 'Ubuntu Mono'; }
    </style>
  </head>
  <body>
    <textarea id="source">

class: center, middle

#C++11 Threading
Manuel Ferreria

Septiembre 2014
---
# Que son los threads?

De guikipedia: **A thread of execution is the smallest sequence of programmed instructions that can be managed independently by a scheduler[...]***

Ayuda memoria: *scheduler* es el modulo del sistema operativo que se encarga de determinar cuales son
los procesos que van a correr en un determinado momento en el procesador.

Los procesos mas sencillos tienen un solo thread,
donde ejecutan todo (interfaz, calculo, conexiones, IO, etc). Nosotros vamos a querer usar multiples
threads, de modo que podamos tener todo corriendo "simultaneamente"

---
#Concurrencia != Paralelismo

- **Paralelismo**: Tener multiples computos ejecutando al mismo tiempo. Las ejecuciones suceden
en el mismo instante.

- **Concurrencia** Tener multiples computos ejecutando concurrentemente, potencialmente
interactuando entre ellos. Aca concurrentemente es en contraposicion a serialmente, uno despues
del otro. Esto no implica que suceden a la vez, sino que durante la vida de los procesos
sus ejecuciones se pueden sobrelapar.

Dicho de otra manera, _paralelo_ describe cosas que pasan simultaneamente en el tiempo, _concurrente_
es un estilo de dise√±o de software que se adapta a que las cosas pasen de manera paralela.

Notar que *no* se puede tener computo en paralelo en un sistema de un unico procesador (single-core).
*Si* se puede tener computo concurrente (como hacen los sistemas operativos).

---

#Donde podemos observar threads?

En las aplicaciones interactivas es fundamental tenerlos para no perder la responsividad de la interfaz.

En bases de datos, se usan para tener multiples transacciones activas.

En servicios web, se usan para mantener conexiones constantes mientras se esperan respuestas.

En videojuegos, para manejar red, graficos e input simultaneamente.

En las aplicaciones de computo cientifico, es la forma de tener todos los procesadores corriendo
porciones de la cuenta.

---
#Ley de Amdhal

Cuando uno usa paralelismo para aumentar la velocidad de lo que esta realizando, tiene que pensar
cuanto es el maximo de velocidad que se puede ganar. La ley de Amdhal dice que si P es
la proporcion de un programa que se beneficia de la paralelizacion, y (1-P) es la proporcion
que debe ser serial necesariamente, entonces _speedup_ maximo lograble usando N procesadores es:

Speedup(N) = 1 /((1-P) + (P / N))

Esto pone la cota en que la parte serial va a terminar siempre dominando, sin importar que tengamos
muchos procesadores.

---
#Ley de Amdhal
![Amdhal](Amdhal.png)

---
#Que problemas tienen los threads?

Los problemas mas tipicos que suelen aparecer en modelos de multiples threads
son las race conditions y deadlocks.

- *Race conditions*: Dos threads leen la misma variable, la aumentan en uno y la escriben. Si ambos
leyeron antes de que uno escriba, la suma del otro se va a perder. No importa mucho en un contador,
pero es critico en una base de datos (piensen banco y transferencia de plata).


- *Deadlocks*: Un thread toma un recurso (por ejemplo, el acceso a la red) y nunca lo libera. El otro thread
toma otro recurso (por ejemplo, la pantalla), y ahora el primer thread pide la pantalla y el segundo la
red. Como ambos estan esperando al otro, nunca van a soltarlo en una liberacion normal.

---
# C++11 Threads 101
```c++
#include <iostream>
#include <thread>

void say_hello() {
  std::cout << "Hola" << std::endl;
}

void say_number(int id) {
  std::cout << "Mi numero es " << id << std::endl;
}

int main() {
  std::thread tl(say_hello);
  tl.join();

  std::thread tArray[10];
  for(int i= 0; i<10; i++) {
*    tArray[i] = std::thread(say_number, i);
  }

  std::cout << "Soy main" <<std::endl;

  for(int i= 0; i<10; i++) {
*    tArray[i].join();
  }
  return 0;
 }
```
---
#C++11 Threads usando archivos de inputs
```c++
#include <iostream>
#include <thread>

void solve(std::string path, int& result);

int main(int argc, char* argv[]) {
  int n_files = argc-1;
  std::vector<std::thread> tArray(n_files-1);
  std::vector<int> solutions(n_files);

  for(int i= 0; i<n_files-1; i++) {
    tArray[i] = std::thread(solve, std::string(argv[i]), &solutions[i] );
  }

  solve(std::string(argv[n_files]), &solutions[n_files]);

  for(auto &t : tArray) {
    t.join();
  }

  for(int i= 0; i<n_files; i++) {
    std::cout << "La solucion " << i << "esima es " << solutions[i] << std::endl;
  }
  return 0;
}
```
---
#Combinando con Lambdas y STL
```c++
#include <iostream>
#include <thread>
#include <vector>
#include <algorithm>

int main() {
  int elems = 100;
  int computation = 0;
  std::vector<int> q(elems, 1);
  std::vector<std::thread> threads;

  std::thread t1([&]() { for (auto & e : q) std::cout << e; } );
  std::thread t2([&](int& res) {for (auto &e : q) res += e; },
                 std::ref(computation));
  threads.push_back(std::move(t1));
  threads.push_back(std::move(t2));

  std::for_each(threads.begin(), threads.end(), [](std::thread &t){ t.join(); });

  std::cout << std::endl << computation << std::endl;
  return 0;
}
```

---
#Que da aca?
```c++
void sumar(const std::vector<int>& s1,
           const std::vector<int>& s2, int L, int R, int& res) {
  for(int i=L; i<R; i++)
    res += s1[i] * s2[i];
}

int main() {
  int sumita = 0;
  int elems = 1000000;
  int number_threads = 2;
  std::vector<int> q(elems,1);
  std::vector<int> w(elems,1);
  std::vector<std::thread> threads;

  for(int i = 0; i< number_threads; i++) {
   threads.push_back(
     std::thread(sumar, q, w,
                 i*(elems/number_threads),
                 (i+1)*(elems/number_threads), std::ref(sumita)));
  }
  for(auto &v : threads) v.join();
  std::cout << "La suma dio " << sumita << std::endl;
  return 0;
}
```
---
# Race condition
```bash

manuel@daneel:/tmp $ g++ -o th -std=c++0x -pthread th.cpp
manuel@daneel:/tmp $ ./th

La suma dio 995398

manuel@daneel:/tmp $ ./th

La suma dio 983266

manuel@daneel:/tmp $ ./th

La suma dio 1000000

manuel@daneel:/tmp $ ./th

La suma dio 998871
```
---
#Mutex y lock_guard

La estructura fundamental de proteccion de la memoria contra las race conditions es el mutex
(mutual exclusion). Se implementa a bajo nivel como una instruccion de assembler que
se ejecuta en un ciclo, y da exito o falla. Esto permite determinar una variable que los
threads van a intentar tomar, y si lo logran, pueden proceder a hacer lo que tenian que hacer.
Si no lo logran, van a seguir esperando hasta que este disponible.

En C++11, las variables de tipo `std::mutex` son obtenidas por el constructor de objetos como
`std::lock_guard` y `std::unique_lock`, y son liberados cuando estos son destruidos (RAII).

Esto garantiza que lo que sigue a std::lock_guard es posible solamente si pudo obtener el
lock.

`std::unique_lock` es similar, salvo que no los obtiene en su creacion sino explicitamente.
Es util para cuando tenemos que adquirir mas de un recurso a la vez (sino podemos entrar
en deadlock, como en el problema tipo de AB y BA)

---
#std::mutex en el ejemplo anterior

```c++
#include <mutex>

*std::mutex safe;

void sumar(const std::vector<int>& s1,
           const std::vector<int>& s2, int L, int R, int& res) {

*           std::lock_guard<std::mutex> lock(safe);

           for(int i=L; i<R; i++)
             res += s1[i] * s2[i];
}
```
---
#Operaciones atomicas

El mutex en el caso anterior sirve para realizar todas las operaciones de manera atomica, indivisible.
La idea es que no nos puedan interrumpir durante un bloque critico de codigo.

C++11 define una libreria `<atomic`> que nos brinda una forma para instanciar variables que sean atomicas, donde
todas las operaciones que se realizen sobre ese dato se garantizan atomicas.

`<atomic`> define `std::atomic<>`, ya especializado en los tipos de datos primitivos enteros:
char, short, int, long, size_t y todos los de longitud fija (de `<cstdint`>)

```c++
#include <atomic>

int main() {
*  std::atomic<int> sumar(0);
  for(int i = 0; i < 100 ; i++ ){
    sumar += i;
  }
  std::cout << sumar << std::endl;
}
```
---
#Async y future

Hasta ahora vimos que para devolver valores de un thread, teniamos que pasar una
referencia a una variable o escribir en algun lugar comun. C++11 define el concepto
de `future`.

`std::async` lanza una funcion f y devuelve instantaneamente una promesa de resultado, un `std::future`.
Esto permite seguir la ejecucion del programa y solamente esperar a ese valor cuando se lo necesite,
permitiendo correr de manera paralela ambos.

Se le pueden pasar parametros a `async`, para forzar de que ejecute la funcion `f` en otro thread,
o que lo haga lazy, que solo la ejecute si alguien pide el future. Ideal para dejar preparadas funciones
que tal vez no se ejecuten.

---
#Async y future

```c++

#include <algorithm>
#include <numeric>
#include <future>

template <typename RAIter>
int parallel_sum(RAIter beg, RAIter end) {
    auto len = std::distance(beg, end);
    if(len < 1000)
        return std::accumulate(beg, end, 0);

    RAIter mid = beg + len/2;
*    auto handle = std::async(std::launch::async,
*                              parallel_sum<RAIter>, mid, end);
*    int sum = parallel_sum(beg, mid);
*    return sum + handle.get();
}

int main() {
    std::vector<int> v(10000, 1);
    std::cout << "The sum is " << parallel_sum(v.begin(), v.end()) << '\n';
}
```
---
#En el fondo, esto es `pthreads`

El estandar POSIX define una API para crear y manipular threads en C. La implementan OS como
FreeBSD, OpenBSD, Linux, OSX, y "Windows" (de manera no nativa).

El estandar define funciones en 4 categorias
- Manejo de threads
- Sincronizacion entre threads
- Mutex
- Variables de condicion

POSIX es la definicion de threads mas usada en la computacion. Los threads en C++ trabajan en una
capa arriba de estos.

---
#Paralelismo automatico: OpenMP

Muchas veces tenemos que hacer aplicaciones donde debemos computar cosas grandes
(procesos sobre imagenes, resolver cuentas matriciales, etc.)

En los procesadores de multiples nucleos vamos a tener que usar tecnicas
concurrentes para poder correr cosas en paralelo. C++11 nos provee muchas herramientas,
con `std::thread` y `std::future`, pero tambien tenemos herramientas mas automaticas,
ya implementadas en muchos compiladores modernos.

Vamos a ver la mas comun y sencilla: *OpenMP*

*OpenMP* es un estandar que define directivas al compilador para que el codigo generado arme threads
y corra las iteraciones del ciclo que acelaramos en threads distintos.
---
#OpenMP 101

```c++

#include <iostream>
#include <vector>

int main() {
  int elementos = 1000*1000;
  int suma = 0;
  std::vector<int> a(elementos, 1);
  std::vector<int> b(elementos, 2);
  std::vector<int> resultado(elementos, 0);

*#pragma omp parallel for
  for(int i=0; i<elementos; i++) {
    resultado[i] = a[i]+b[i];
  }

*#pragma omp parallel for reduce(+:suma)
  for(int i=0; i<elementos; i++) {
    suma += resultado[i];
  }
  std::cout << suma << std::endl;
  return 0;
}

```
---
#OpenMP 101

El `#pragma omp parallel for` es la directiva clave. Aca decimos que el ciclo `for` siguiente
puede ser paralelizado. A esta se le pueden agregar otras directivas que hablen de las
variables ya definidas en el contexto:
- `shared()` dice que esas variables son compartidas entre todos los threads, pero
no tienen un mutex por defecto, eso nos corresponde a nosotros agregarlo.

- `private()` dice que esas variables no son compartidas, por lo cual cada thread tiene su copia de esta.

- `reduce()` dice que las variables que se usen para reducir, al final de todo el proceso, deben
ser reducidas entre si de la forma definida. Otras reducciones son `*`, `&&`, `||`.

OpenMP por default crea un *pool* de threads, tantos como procesadores virtuales tenga la
maquina (incluyendo el hyperthreading, digamos). Esto se hace porque crear threads es
costoso cuando su vida puede ser relativamente corta. Cuando termina una iteracion, se le
carga a ese thread que termino la nueva iteracion a procesar.

---
# Seccion Critica

```c++
#pragma omp parallel for
  for(int i=0; i<elementos; i++) {
    while(tmp > 0) {
      printf("%d", tmp % 10);
      tmp = tmp / 10;
    }
  }
```
Que pasa si dos threads entran en el `while` al mismo tiempo?
--

```c++
#pragma omp parallel for
  for(int i=0; i<elementos; i++) {
    int tmp = a[i]+b[i];
*    #pragma omp critical
    {
      while(tmp > 0) {
        printf("%d", tmp % 10);
        tmp = tmp / 10;
      }
    }
  }

```
---
# Barreras


---
#Ojo con OpenMP

Cosas importantes que tenemos que tener en cuenta para usar la paralelizacion automatica:
- Las iteraciones del ciclo deben ser independientes: no es util esta estrategia de paralelizacion
si para hacer el paso i-esimo, necesitamos los datos i-1 esimo.

- Las iteraciones deben tener una cantidad no-trivial de trabajo que hacer.

- No debemos modificar la condicion de la iteracion durante la ejecucion.

- Hay que agregar al `parallel for` directivas adicionales para especificar el comportamiento
de las variables del contexto


---
#

    </textarea>
    <script src="http://gnab.github.io/remark/downloads/remark-latest.min.js" type="text/javascript"> </script>
    <script type="text/javascript">
      var slideshow = remark.create();
    </script>
  </body>
</html>
