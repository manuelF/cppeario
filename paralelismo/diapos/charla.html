<!DOCTYPE html>
<html>
  <head>
    <title>Title</title>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
    <style type="text/css">
      @import url(http://fonts.googleapis.com/css?family=Yanone+Kaffeesatz);
      @import url(http://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic);
      @import url(http://fonts.googleapis.com/css?family=Ubuntu+Mono:400,700,400italic);

      body { font-family: 'Droid Serif'; }
      h1, h2, h3 {
        font-family: 'Yanone Kaffeesatz';
        font-weight: normal;
      }
      .remark-code, .remark-inline-code { font-family: 'Ubuntu Mono'; }
    </style>
  </head>
  <body>
    <textarea id="source">

class: center, middle

#C++11 Threading
Manuel Ferreria

Septiembre 2014
---
# Que son los threads?

De guikipedia: **A thread of execution is the smallest sequence of programmed instructions that can be managed independently by a scheduler[...]***

Ayuda memoria: *scheduler* es el modulo del sistema operativo que se encarga de determinar cuales son
los procesos que van a correr en un determinado momento en el procesador.

Los procesos mas sencillos tienen un solo thread,
donde ejecutan todo (interfaz, calculo, conexiones, IO, etc). Nosotros vamos a querer usar multiples
threads, de modo que podamos tener todo corriendo "simultaneamente"

---
#Concurrencia != Paralelismo

- **Paralelismo**: Tener multiples computos ejecutando al mismo tiempo. Las ejecuciones suceden
en el mismo instante.

- **Concurrencia** Tener multiples computos ejecutando concurrentemente, potencialmente
interactuando entre ellos. Aca concurrentemente es en contraposicion a serialmente, uno despues
del otro. Esto no implica que suceden a la vez, sino que durante la vida de los procesos
sus ejecuciones se pueden sobrelapar.

Notar que no se puede tener computo en paralelo en un sistema de un unico procesador (single-core).
Si se puede tener computo concurrente (como hacen los sistemas operativos).

---

#Donde podemos observar threads?

En las aplicaciones interactivas es fundamental tenerlos para no perder la responsividad de la interfaz.

En bases de datos, se usan para tener multiples transacciones activas.

En servicios web, se usan para mantener conexiones constantes mientras se esperan respuestas.

En videojuegos, para manejar red, graficos e input simultaneamente.

En las aplicaciones de computo cientifico, es la forma de tener todos los procesadores corriendo
porciones de la cuenta.

---
#Que problemas tienen los threads?

Los problemas mas tipicos que suelen aparecer en modelos de multiples threads
son las race conditions y deadlocks.

- *Race conditions*: Dos threads leen la misma variable, la aumentan en uno y la escriben. Si ambos
leyeron antes de que uno escriba, la suma del otro se va a perder. No importa mucho en un contador,
pero es critico en una base de datos (piensen banco y transferencia de plata).


- *Deadlocks*: Un thread toma un recurso (por ejemplo, el acceso a la red) y nunca lo libera. El otro thread
toma otro recurso (por ejemplo, la pantalla), y ahora el primer thread pide la pantalla y el segundo la
red. Como ambos estan esperando al otro, nunca van a soltarlo en una liberacion normal.

---
# C++11 Threads 101
```c++
#include <iostream>
#include <thread>

void say_hello() {
  std::cout << "Hola" << std::endl;
}

void say_number(int id) {
  std::cout << "Mi numero es " << id << std::endl;
}

int main() {
  std::thread tl(say_hello);
  tl.join();

  std::thread tArray[10];
  for(int i= 0; i<10; i++) {
*    tArray[i] = std::thread(say_number, i);
  }

  std::cout << "Soy main" <<std::endl;

  for(int i= 0; i<10; i++) {
*    tArray[i].join();
  }
  return 0;
 }
```
---
#C++11 Threads usando archivos de inputs
```c++
#include <iostream>
#include <thread>

void solve(std::string path, int& result);

int main(int argc, char* argv[]) {
  int n_files = argc-1;
  std::vector<std::thread> tArray(n_files-1);
  std::vector<int> solutions(n_files);

  for(int i= 0; i<n_files-1; i++) {
    tArray[i] = std::thread(solve, std::string(argv[i]), &solutions[i] );
  }

  solve(std::string(argv[n_files]), &solutions[n_files]);

  for(auto &t : tArray) {
    t.join();
  }

  for(int i= 0; i<n_files; i++) {
    std::cout << "La solucion " << i << "esima es " << solutions[i] << std::endl;
  }
  return 0;
}
```
---
#Combinando con Lambdas y STL
```c++
#include <iostream>
#include <thread>
#include <vector>
#include <algorithm>

int main() {
  int elems = 100;
  int computation = 0;
  std::vector<int> q(elems, 1);
  std::vector<std::thread> threads;

  std::thread t1([&]() { for (auto & e : q) std::cout << e; } );
  std::thread t2([&](int& res) {for (auto &e : q) res += e; },
                 std::ref(computation));
  threads.push_back(std::move(t1));
  threads.push_back(std::move(t2));

  std::for_each(threads.begin(), threads.end(), [](std::thread &t){ t.join(); });

  std::cout << std::endl << computation << std::endl;
  return 0;
}
```

---
#Que da aca?
```c++
void sumar(const std::vector<int>& s1,
           const std::vector<int>& s2, int L, int R, int& res) {
  for(int i=L; i<R; i++)
    res += s1[i] * s2[i];
}

int main() {
  int sumita = 0;
  int elems = 1000000;
  int number_threads = 2;
  std::vector<int> q(elems,1);
  std::vector<int> w(elems,1);
  std::vector<std::thread> threads;

  for(int i = 0; i< number_threads; i++) {
   threads.push_back(
     std::thread(sumar, q, w,
                 i*(elems/number_threads),
                 (i+1)*(elems/number_threads), std::ref(sumita)));
  }
  for(auto &v : threads) v.join();
  std::cout << "La suma dio " << sumita << std::endl;
  return 0;
}
```
---
# Race condition
```bash

manuel@daneel:/tmp $ g++ -o th -std=c++0x -pthread th.cpp
manuel@daneel:/tmp $ ./th

La suma dio 995398

manuel@daneel:/tmp $ ./th

La suma dio 983266

manuel@daneel:/tmp $ ./th

La suma dio 1000000

manuel@daneel:/tmp $ ./th

La suma dio 998871
```
---
#Mutex y lock_guard

La estructura fundamental de proteccion de la memoria contra las race conditions es el mutex
(mutual exclusion). Se implementa a bajo nivel como una instruccion de assembler que
se ejecuta en un ciclo, y da exito o falla. Esto permite determinar una variable que los
threads van a intentar tomar, y si lo logran, pueden proceder a hacer lo que tenian que hacer.
Si no lo logran, van a seguir esperando hasta que este disponible.

En C++11, las variables de tipo `std::mutex` son obtenidas por el constructor de objetos como
`std::lock_guard` y `std::unique_lock`, y son liberados cuando estos son destruidos (RAII).

Esto garantiza que lo que sigue a std::lock_guard es posible solamente si pudo obtener el
lock.

`std::unique_lock` es similar, salvo que no los obtiene en su creacion sino explicitamente.
Es util para cuando tenemos que adquirir mas de un recurso a la vez (sino podemos entrar
en deadlock, como en el problema tipo de AB y BA)

---
#std::mutex en el ejemplo anterior

```c++
#include <mutex>

*std::mutex safe;

void sumar(const std::vector<int>& s1,
           const std::vector<int>& s2, int L, int R, int& res) {

*           std::lock_guard<std::mutex> lock(safe);

           for(int i=L; i<R; i++)
             res += s1[i] * s2[i];
}
```
---
#Operaciones atomicas

El mutex en el caso anterior sirve para realizar todas las operaciones de manera atomica, indivisible.
La idea es que no nos puedan interrumpir durante un bloque critico de codigo.

C++11 define una libreria `<atomic`> que nos brinda una forma para instanciar variables que sean atomicas, donde
todas las operaciones que se realizen sobre ese dato se garantizan atomicas.

`<atomic`> define `std::atomic<>`, ya especializado en los tipos de datos primitivos enteros:
char, short, int, long, size_t y todos los de longitud fija (de `<cstdint`>)

```c++
#include <atomic>

int main() {
*  std::atomic<int> sumar(0);
  for(int i = 0; i < 100 ; i++ ){
    sumar += i;
  }
  std::cout << sumar << std::endl;
}
```
---
#Async y future

Hasta ahora vimos que para devolver valores de un thread, teniamos que pasar una
referencia a una variable o escribir en algun lugar comun. C++11 define el concepto
de `future`.

`std::async` lanza una funcion f y devuelve instantaneamente una promesa de resultado, un `std::future`.
Esto permite seguir la ejecucion del programa y solamente esperar a ese valor cuando se lo necesite,
permitiendo correr de manera paralela ambos.

Se le pueden pasar parametros a `async`, para forzar de que ejecute la funcion `f` en otro thread,
o que lo haga lazy, que solo la ejecute si alguien pide el future. Ideal para dejar preparadas funciones
que tal vez no se ejecuten.

---
#Async y future

```c++

#include <algorithm>
#include <numeric>
#include <future>

template <typename RAIter>
int parallel_sum(RAIter beg, RAIter end) {
    auto len = std::distance(beg, end);
    if(len < 1000)
        return std::accumulate(beg, end, 0);

    RAIter mid = beg + len/2;
*    auto handle = std::async(std::launch::async,
*                              parallel_sum<RAIter>, mid, end);
*    int sum = parallel_sum(beg, mid);
*    return sum + handle.get();
}

int main() {
    std::vector<int> v(10000, 1);
    std::cout << "The sum is " << parallel_sum(v.begin(), v.end()) << '\n';
}
```
---

#pthreads

El estandar POSIX define una API para crear y manipular threads en C. La implementan OS como
FreeBSD, OpenBSD, Linux, OSX, y "Windows" (de manera no nativa).

El estandar define funciones en 4 categorias
- Manejo de threads
- Sincronizacion entre threads
- Mutex
- Variables de condicion

POSIX es la definicion de threads mas usada en la computacion. Los threads en C++ trabajan en una
capa arriba de estos.

---
#

    </textarea>
    <script src="http://gnab.github.io/remark/downloads/remark-latest.min.js" type="text/javascript">
    </script>
    <script type="text/javascript">
      var slideshow = remark.create();
    </script>
  </body>
</html>
